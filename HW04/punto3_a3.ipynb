{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PUNTO 3 - ARQUITECTURA 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descarga de librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.layers import Embedding, Flatten, Dense, Dropout\n",
    "import os\n",
    "from gensim.utils import simple_preprocess\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.layers import Dense, Embedding, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESAMIENTO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se encontraron 9 libros en la carpeta /books\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "books_folder = './books/'\n",
    "\n",
    "\n",
    "book_files = [f for f in os.listdir(books_folder) if f.endswith('.txt')]\n",
    "\n",
    "names = []\n",
    "books_texts = []\n",
    "for book_file in book_files:\n",
    "    with open(os.path.join(books_folder, book_file), 'r', encoding='utf-8') as file:\n",
    "        books_texts.append(file.read())\n",
    "        names.append(book_file.split('_')[0])\n",
    "\n",
    "print(f'Se encontraron {len(book_files)} libros en la carpeta /books')\n",
    "processed_books = [\" \".join(simple_preprocess(text)) for text in books_texts]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividir textos en fragmentos con su respectiva etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_fragments(text, fragment_size=150):\n",
    "    words = text.split()\n",
    "    fragments = [words[i:i + fragment_size] for i in range(0, len(words), fragment_size)]\n",
    "    return [' '.join(fragment) for fragment in fragments]\n",
    "\n",
    "\n",
    "fragment_size = 150  \n",
    "fragmented_books = []\n",
    "fragment_labels = []\n",
    "\n",
    "for i, book_text in enumerate(books_texts):\n",
    "    fragments = split_into_fragments(book_text, fragment_size=fragment_size)\n",
    "    fragmented_books.extend(fragments)\n",
    "    fragment_labels.extend([names[i]] * len(fragments))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revision de fragmentos por etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7553\n",
      "{'tolstoy': 4544, 'forster': 1520, 'vonarnin': 1489}\n"
     ]
    }
   ],
   "source": [
    "print(len(fragment_labels))\n",
    "dic = {}\n",
    "for i in fragment_labels:\n",
    "    dic[i] = dic.get(i, 0)+ 1\n",
    "\n",
    "print(dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(fragmented_books)\n",
    "X = tokenizer.texts_to_sequences(fragmented_books)\n",
    "\n",
    "X = pad_sequences(X, maxlen=fragment_size)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(fragment_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Division entre test y train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creacion de la matriz de embeddings pre entrenados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings de tamaño 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec  \n",
    "embedding_model_3 = Word2Vec.load('Books_300_EMF.model')\n",
    "vocab_size = len(tokenizer.word_index) + 1  \n",
    "embedding_dim_3 = embedding_model_3.vector_size  \n",
    "embedding_matrix_3 = np.zeros((vocab_size, embedding_dim_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, idx in tokenizer.word_index.items():\n",
    "    if word in embedding_model_3.wv:\n",
    "        embedding_matrix_3[idx] = embedding_model_3.wv[word]\n",
    "    else:\n",
    "        embedding_matrix_3[idx] = np.zeros(embedding_dim_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding de tamaño 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec  \n",
    "embedding_model_2 = Word2Vec.load('Books_200_EMF.model')\n",
    "vocab_size = len(tokenizer.word_index) + 1  \n",
    "embedding_dim_2 = embedding_model_2.vector_size  \n",
    "embedding_matrix_2 = np.zeros((vocab_size, embedding_dim_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, idx in tokenizer.word_index.items():\n",
    "    if word in embedding_model_2.wv:\n",
    "        embedding_matrix_2[idx] = embedding_model_2.wv[word]\n",
    "    else:\n",
    "        embedding_matrix_2[idx] = np.zeros(embedding_dim_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings de tamaño 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec  \n",
    "embedding_model = Word2Vec.load('Books_100_EMF.model')\n",
    "vocab_size = len(tokenizer.word_index) + 1  \n",
    "embedding_dim = embedding_model.vector_size  \n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, idx in tokenizer.word_index.items():\n",
    "    if word in embedding_model.wv:\n",
    "        embedding_matrix[idx] = embedding_model.wv[word]\n",
    "    else:\\\n",
    "        embedding_matrix[idx] = np.zeros(embedding_dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creacion de la red feed-forward: Arquitectura 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings tamaño 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = Sequential()\n",
    "model_3.add(Embedding(input_dim=vocab_size, \n",
    "                    output_dim=embedding_dim_3, \n",
    "                    weights=[embedding_matrix_3],  \n",
    "                    input_length=fragment_size,  \n",
    "                    trainable=False))  \n",
    "\n",
    "model_3.add(Flatten()) \n",
    "model_3.add(Dense(128, activation='relu')) \n",
    "model_3.add(Dropout(0.5))\n",
    "model_3.add(Dense(64, activation='relu'))   \n",
    "model_3.add(Dense(len(set(names)), activation='softmax'))  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings tamaño 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'forster', 'tolstoy', 'vonarnin'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 3635, 1: 3635, 2: 3635}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "class_distribution = dict(zip(unique, counts))\n",
    "print(class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(Embedding(input_dim=vocab_size, \n",
    "                    output_dim=embedding_dim_2, \n",
    "                    weights=[embedding_matrix_2],  \n",
    "                    input_length=fragment_size,  \n",
    "                    trainable=False))  \n",
    "\n",
    "model_2.add(Flatten()) \n",
    "model_2.add(Dense(128, activation='relu')) \n",
    "model_2.add(Dropout(0.5))\n",
    "model_2.add(Dense(64, activation='relu'))   \n",
    "model_2.add(Dense(len(set(names)), activation='softmax'))  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings tamaño 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, \n",
    "                    output_dim=embedding_dim, \n",
    "                    weights=[embedding_matrix],  \n",
    "                    input_length=fragment_size,  \n",
    "                    trainable=False))  \n",
    "\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(128, activation='relu')) \n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))   \n",
    "model.add(Dense(len(set(names)), activation='softmax'))  #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de la red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings tamaño 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "341/341 [==============================] - 2s 5ms/step - loss: 1.1163 - accuracy: 0.3446 - val_loss: 1.0872 - val_accuracy: 0.3817\n",
      "Epoch 2/100\n",
      "341/341 [==============================] - 2s 6ms/step - loss: 1.0903 - accuracy: 0.3724 - val_loss: 1.0775 - val_accuracy: 0.4063\n",
      "Epoch 3/100\n",
      "341/341 [==============================] - 2s 6ms/step - loss: 1.0735 - accuracy: 0.3857 - val_loss: 1.0824 - val_accuracy: 0.4067\n",
      "Epoch 4/100\n",
      "341/341 [==============================] - 2s 6ms/step - loss: 1.0492 - accuracy: 0.4212 - val_loss: 1.0340 - val_accuracy: 0.4613\n",
      "Epoch 5/100\n",
      "341/341 [==============================] - 2s 6ms/step - loss: 1.0240 - accuracy: 0.4464 - val_loss: 1.0119 - val_accuracy: 0.4697\n",
      "Epoch 6/100\n",
      "341/341 [==============================] - 2s 6ms/step - loss: 0.9960 - accuracy: 0.4757 - val_loss: 0.9868 - val_accuracy: 0.5061\n",
      "Epoch 7/100\n",
      "341/341 [==============================] - 2s 6ms/step - loss: 0.9729 - accuracy: 0.4989 - val_loss: 0.9620 - val_accuracy: 0.5438\n",
      "Epoch 8/100\n",
      "341/341 [==============================] - 2s 6ms/step - loss: 0.9451 - accuracy: 0.5154 - val_loss: 0.9241 - val_accuracy: 0.5570\n",
      "Epoch 9/100\n",
      "341/341 [==============================] - 2s 6ms/step - loss: 0.9252 - accuracy: 0.5258 - val_loss: 0.9252 - val_accuracy: 0.5592\n",
      "Epoch 10/100\n",
      "341/341 [==============================] - 2s 7ms/step - loss: 0.9002 - accuracy: 0.5523 - val_loss: 0.8990 - val_accuracy: 0.5856\n",
      "Epoch 11/100\n",
      "341/341 [==============================] - 2s 6ms/step - loss: 0.8846 - accuracy: 0.5643 - val_loss: 0.8720 - val_accuracy: 0.6058\n",
      "Epoch 12/100\n",
      "341/341 [==============================] - 2s 7ms/step - loss: 0.8592 - accuracy: 0.5762 - val_loss: 0.8737 - val_accuracy: 0.6040\n",
      "Epoch 13/100\n",
      "341/341 [==============================] - 2s 5ms/step - loss: 0.8498 - accuracy: 0.5853 - val_loss: 0.8794 - val_accuracy: 0.6153\n",
      "Epoch 14/100\n",
      "341/341 [==============================] - 2s 6ms/step - loss: 0.8517 - accuracy: 0.5858 - val_loss: 0.8563 - val_accuracy: 0.6300\n",
      "Epoch 15/100\n",
      "341/341 [==============================] - 2s 6ms/step - loss: 0.8276 - accuracy: 0.6034 - val_loss: 0.8468 - val_accuracy: 0.6362\n",
      "Epoch 16/100\n",
      "341/341 [==============================] - 2s 6ms/step - loss: 0.8083 - accuracy: 0.6125 - val_loss: 0.8128 - val_accuracy: 0.6601\n",
      "Epoch 17/100\n",
      "341/341 [==============================] - 2s 6ms/step - loss: 0.7914 - accuracy: 0.6211 - val_loss: 0.8265 - val_accuracy: 0.6564\n",
      "Epoch 18/100\n",
      "341/341 [==============================] - 2s 6ms/step - loss: 0.7823 - accuracy: 0.6311 - val_loss: 0.8127 - val_accuracy: 0.6659\n",
      "Epoch 19/100\n",
      "341/341 [==============================] - 2s 6ms/step - loss: 0.7685 - accuracy: 0.6426 - val_loss: 0.8005 - val_accuracy: 0.6641\n",
      "Epoch 20/100\n",
      "341/341 [==============================] - 2s 7ms/step - loss: 0.7584 - accuracy: 0.6540 - val_loss: 0.7868 - val_accuracy: 0.6740\n",
      "Epoch 21/100\n",
      "341/341 [==============================] - 2s 6ms/step - loss: 0.7511 - accuracy: 0.6494 - val_loss: 0.7735 - val_accuracy: 0.6835\n",
      "Epoch 22/100\n",
      "341/341 [==============================] - 2s 6ms/step - loss: 0.7492 - accuracy: 0.6518 - val_loss: 0.7771 - val_accuracy: 0.6758\n",
      "Epoch 23/100\n",
      "341/341 [==============================] - 2s 6ms/step - loss: 0.7410 - accuracy: 0.6568 - val_loss: 0.7672 - val_accuracy: 0.6821\n",
      "Epoch 24/100\n",
      "341/341 [==============================] - 2s 6ms/step - loss: 0.7214 - accuracy: 0.6641 - val_loss: 0.7734 - val_accuracy: 0.6890\n",
      "Epoch 25/100\n",
      "341/341 [==============================] - 3s 8ms/step - loss: 0.7137 - accuracy: 0.6765 - val_loss: 0.7626 - val_accuracy: 0.6909\n",
      "Epoch 26/100\n",
      "341/341 [==============================] - 2s 7ms/step - loss: 0.7112 - accuracy: 0.6734 - val_loss: 0.7420 - val_accuracy: 0.6993\n",
      "Epoch 27/100\n",
      "341/341 [==============================] - 2s 7ms/step - loss: 0.7026 - accuracy: 0.6776 - val_loss: 0.7645 - val_accuracy: 0.6920\n",
      "Epoch 28/100\n",
      "341/341 [==============================] - 2s 7ms/step - loss: 0.6984 - accuracy: 0.6842 - val_loss: 0.7576 - val_accuracy: 0.6876\n",
      "Epoch 29/100\n",
      "341/341 [==============================] - 2s 6ms/step - loss: 0.7051 - accuracy: 0.6753 - val_loss: 0.7453 - val_accuracy: 0.7015\n",
      "Epoch 30/100\n",
      "341/341 [==============================] - 2s 6ms/step - loss: 0.6813 - accuracy: 0.6894 - val_loss: 0.7383 - val_accuracy: 0.7033\n",
      "Epoch 31/100\n",
      "341/341 [==============================] - 3s 8ms/step - loss: 0.6712 - accuracy: 0.6982 - val_loss: 0.7468 - val_accuracy: 0.7162\n",
      "Epoch 32/100\n",
      "341/341 [==============================] - 3s 8ms/step - loss: 0.6628 - accuracy: 0.7062 - val_loss: 0.7444 - val_accuracy: 0.7195\n",
      "Epoch 33/100\n",
      "341/341 [==============================] - 2s 5ms/step - loss: 0.6585 - accuracy: 0.7069 - val_loss: 0.7435 - val_accuracy: 0.7092\n",
      "Epoch 34/100\n",
      "341/341 [==============================] - 2s 6ms/step - loss: 0.6573 - accuracy: 0.7059 - val_loss: 0.7388 - val_accuracy: 0.7037\n",
      "Epoch 35/100\n",
      "341/341 [==============================] - 2s 7ms/step - loss: 0.6509 - accuracy: 0.7101 - val_loss: 0.7725 - val_accuracy: 0.6887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x356a82e50>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings tamaño 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "341/341 [==============================] - 5s 12ms/step - loss: 1.1270 - accuracy: 0.3473 - val_loss: 1.0833 - val_accuracy: 0.4015\n",
      "Epoch 2/100\n",
      "341/341 [==============================] - 4s 10ms/step - loss: 1.0967 - accuracy: 0.3571 - val_loss: 1.0890 - val_accuracy: 0.3762\n",
      "Epoch 3/100\n",
      "341/341 [==============================] - 3s 9ms/step - loss: 1.0889 - accuracy: 0.3550 - val_loss: 1.0788 - val_accuracy: 0.3729\n",
      "Epoch 4/100\n",
      "341/341 [==============================] - 3s 9ms/step - loss: 1.0767 - accuracy: 0.3725 - val_loss: 1.0673 - val_accuracy: 0.3825\n",
      "Epoch 5/100\n",
      "341/341 [==============================] - 3s 10ms/step - loss: 1.0605 - accuracy: 0.3836 - val_loss: 1.0416 - val_accuracy: 0.4338\n",
      "Epoch 6/100\n",
      "341/341 [==============================] - 4s 11ms/step - loss: 1.0573 - accuracy: 0.3893 - val_loss: 1.0531 - val_accuracy: 0.3997\n",
      "Epoch 7/100\n",
      "341/341 [==============================] - 3s 9ms/step - loss: 1.0448 - accuracy: 0.3926 - val_loss: 1.0303 - val_accuracy: 0.4393\n",
      "Epoch 8/100\n",
      "341/341 [==============================] - 3s 9ms/step - loss: 1.0340 - accuracy: 0.4014 - val_loss: 1.0239 - val_accuracy: 0.4507\n",
      "Epoch 9/100\n",
      "341/341 [==============================] - 4s 11ms/step - loss: 1.0299 - accuracy: 0.4093 - val_loss: 1.0210 - val_accuracy: 0.4371\n",
      "Epoch 10/100\n",
      "341/341 [==============================] - 3s 10ms/step - loss: 1.0224 - accuracy: 0.4161 - val_loss: 1.0144 - val_accuracy: 0.4411\n",
      "Epoch 11/100\n",
      "341/341 [==============================] - 3s 10ms/step - loss: 1.0114 - accuracy: 0.4249 - val_loss: 1.0190 - val_accuracy: 0.4320\n",
      "Epoch 12/100\n",
      "341/341 [==============================] - 4s 11ms/step - loss: 1.0064 - accuracy: 0.4381 - val_loss: 0.9869 - val_accuracy: 0.4668\n",
      "Epoch 13/100\n",
      "341/341 [==============================] - 4s 11ms/step - loss: 1.0012 - accuracy: 0.4346 - val_loss: 0.9891 - val_accuracy: 0.4708\n",
      "Epoch 14/100\n",
      "341/341 [==============================] - 4s 12ms/step - loss: 0.9937 - accuracy: 0.4436 - val_loss: 0.9854 - val_accuracy: 0.4826\n",
      "Epoch 15/100\n",
      "341/341 [==============================] - 4s 11ms/step - loss: 0.9828 - accuracy: 0.4497 - val_loss: 0.9811 - val_accuracy: 0.4785\n",
      "Epoch 16/100\n",
      "341/341 [==============================] - 3s 10ms/step - loss: 0.9740 - accuracy: 0.4559 - val_loss: 0.9575 - val_accuracy: 0.4987\n",
      "Epoch 17/100\n",
      "341/341 [==============================] - 3s 10ms/step - loss: 0.9673 - accuracy: 0.4674 - val_loss: 0.9672 - val_accuracy: 0.4961\n",
      "Epoch 18/100\n",
      "341/341 [==============================] - 4s 13ms/step - loss: 0.9595 - accuracy: 0.4711 - val_loss: 0.9539 - val_accuracy: 0.4972\n",
      "Epoch 19/100\n",
      "341/341 [==============================] - 5s 13ms/step - loss: 0.9504 - accuracy: 0.4764 - val_loss: 0.9413 - val_accuracy: 0.5171\n",
      "Epoch 20/100\n",
      "341/341 [==============================] - 4s 11ms/step - loss: 0.9400 - accuracy: 0.4890 - val_loss: 0.9499 - val_accuracy: 0.5061\n",
      "Epoch 21/100\n",
      "341/341 [==============================] - 4s 10ms/step - loss: 0.9313 - accuracy: 0.4939 - val_loss: 0.9277 - val_accuracy: 0.5321\n",
      "Epoch 22/100\n",
      "341/341 [==============================] - 3s 9ms/step - loss: 0.9318 - accuracy: 0.4963 - val_loss: 0.9080 - val_accuracy: 0.5457\n",
      "Epoch 23/100\n",
      "341/341 [==============================] - 3s 10ms/step - loss: 0.9209 - accuracy: 0.5081 - val_loss: 0.9542 - val_accuracy: 0.5174\n",
      "Epoch 24/100\n",
      "341/341 [==============================] - 5s 14ms/step - loss: 0.9104 - accuracy: 0.5098 - val_loss: 0.9165 - val_accuracy: 0.5416\n",
      "Epoch 25/100\n",
      "341/341 [==============================] - 4s 11ms/step - loss: 0.9027 - accuracy: 0.5162 - val_loss: 0.9271 - val_accuracy: 0.5383\n",
      "Epoch 26/100\n",
      "341/341 [==============================] - 3s 9ms/step - loss: 0.9001 - accuracy: 0.5230 - val_loss: 0.9181 - val_accuracy: 0.5358\n",
      "Epoch 27/100\n",
      "341/341 [==============================] - 3s 10ms/step - loss: 0.8900 - accuracy: 0.5272 - val_loss: 0.9147 - val_accuracy: 0.5405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x357de1850>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping_2 = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "model_2.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 4ms/step - loss: 0.9080 - accuracy: 0.5457\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings tamaño 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "341/341 [==============================] - 5s 14ms/step - loss: 1.1353 - accuracy: 0.3340 - val_loss: 1.0895 - val_accuracy: 0.3678\n",
      "Epoch 2/100\n",
      "341/341 [==============================] - 5s 16ms/step - loss: 1.0894 - accuracy: 0.3621 - val_loss: 1.1277 - val_accuracy: 0.3920\n",
      "Epoch 3/100\n",
      "341/341 [==============================] - 6s 16ms/step - loss: 1.0833 - accuracy: 0.3762 - val_loss: 1.0686 - val_accuracy: 0.4114\n",
      "Epoch 4/100\n",
      "341/341 [==============================] - 5s 13ms/step - loss: 1.0702 - accuracy: 0.3938 - val_loss: 1.0515 - val_accuracy: 0.4217\n",
      "Epoch 5/100\n",
      "341/341 [==============================] - 8s 23ms/step - loss: 1.0573 - accuracy: 0.3972 - val_loss: 1.0381 - val_accuracy: 0.4393\n",
      "Epoch 6/100\n",
      "341/341 [==============================] - 5s 15ms/step - loss: 1.0511 - accuracy: 0.4084 - val_loss: 1.0504 - val_accuracy: 0.4448\n",
      "Epoch 7/100\n",
      "341/341 [==============================] - 5s 15ms/step - loss: 1.0440 - accuracy: 0.4094 - val_loss: 1.0097 - val_accuracy: 0.4650\n",
      "Epoch 8/100\n",
      "341/341 [==============================] - 6s 19ms/step - loss: 1.0261 - accuracy: 0.4242 - val_loss: 1.0212 - val_accuracy: 0.4459\n",
      "Epoch 9/100\n",
      "341/341 [==============================] - 7s 19ms/step - loss: 1.0115 - accuracy: 0.4414 - val_loss: 1.0040 - val_accuracy: 0.4840\n",
      "Epoch 10/100\n",
      "341/341 [==============================] - 6s 17ms/step - loss: 1.0016 - accuracy: 0.4451 - val_loss: 0.9914 - val_accuracy: 0.4818\n",
      "Epoch 11/100\n",
      "341/341 [==============================] - 4s 13ms/step - loss: 0.9952 - accuracy: 0.4551 - val_loss: 0.9669 - val_accuracy: 0.5009\n",
      "Epoch 12/100\n",
      "341/341 [==============================] - 5s 15ms/step - loss: 0.9773 - accuracy: 0.4662 - val_loss: 0.9587 - val_accuracy: 0.5061\n",
      "Epoch 13/100\n",
      "341/341 [==============================] - 5s 15ms/step - loss: 0.9736 - accuracy: 0.4766 - val_loss: 0.9550 - val_accuracy: 0.5284\n",
      "Epoch 14/100\n",
      "341/341 [==============================] - 6s 17ms/step - loss: 0.9589 - accuracy: 0.4819 - val_loss: 0.9465 - val_accuracy: 0.5314\n",
      "Epoch 15/100\n",
      "341/341 [==============================] - 5s 16ms/step - loss: 0.9546 - accuracy: 0.4836 - val_loss: 0.9574 - val_accuracy: 0.5314\n",
      "Epoch 16/100\n",
      "341/341 [==============================] - 4s 13ms/step - loss: 0.9620 - accuracy: 0.4863 - val_loss: 0.9405 - val_accuracy: 0.5306\n",
      "Epoch 17/100\n",
      "341/341 [==============================] - 5s 14ms/step - loss: 0.9422 - accuracy: 0.4985 - val_loss: 0.9320 - val_accuracy: 0.5405\n",
      "Epoch 18/100\n",
      "341/341 [==============================] - 5s 14ms/step - loss: 0.9314 - accuracy: 0.5113 - val_loss: 0.9234 - val_accuracy: 0.5592\n",
      "Epoch 19/100\n",
      "341/341 [==============================] - 8s 24ms/step - loss: 0.9227 - accuracy: 0.5157 - val_loss: 0.9221 - val_accuracy: 0.5541\n",
      "Epoch 20/100\n",
      "341/341 [==============================] - 5s 15ms/step - loss: 0.9162 - accuracy: 0.5165 - val_loss: 0.9271 - val_accuracy: 0.5442\n",
      "Epoch 21/100\n",
      "341/341 [==============================] - 6s 17ms/step - loss: 0.9095 - accuracy: 0.5282 - val_loss: 0.8942 - val_accuracy: 0.5728\n",
      "Epoch 22/100\n",
      "341/341 [==============================] - 5s 16ms/step - loss: 0.9042 - accuracy: 0.5329 - val_loss: 0.9004 - val_accuracy: 0.5658\n",
      "Epoch 23/100\n",
      "341/341 [==============================] - 5s 14ms/step - loss: 0.8970 - accuracy: 0.5368 - val_loss: 0.9105 - val_accuracy: 0.5545\n",
      "Epoch 24/100\n",
      "341/341 [==============================] - 6s 16ms/step - loss: 0.8974 - accuracy: 0.5376 - val_loss: 0.9004 - val_accuracy: 0.5768\n",
      "Epoch 25/100\n",
      "341/341 [==============================] - 5s 13ms/step - loss: 0.8800 - accuracy: 0.5485 - val_loss: 0.8663 - val_accuracy: 0.5955\n",
      "Epoch 26/100\n",
      "341/341 [==============================] - 5s 16ms/step - loss: 0.8688 - accuracy: 0.5567 - val_loss: 0.8923 - val_accuracy: 0.5669\n",
      "Epoch 27/100\n",
      "341/341 [==============================] - 5s 15ms/step - loss: 0.8677 - accuracy: 0.5540 - val_loss: 0.8905 - val_accuracy: 0.5801\n",
      "Epoch 28/100\n",
      "341/341 [==============================] - 5s 14ms/step - loss: 0.8616 - accuracy: 0.5595 - val_loss: 0.8820 - val_accuracy: 0.5864\n",
      "Epoch 29/100\n",
      "341/341 [==============================] - 5s 13ms/step - loss: 0.8580 - accuracy: 0.5636 - val_loss: 0.8888 - val_accuracy: 0.5853\n",
      "Epoch 30/100\n",
      "341/341 [==============================] - 5s 14ms/step - loss: 0.8537 - accuracy: 0.5680 - val_loss: 0.8966 - val_accuracy: 0.5827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x35b382a30>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping_3 = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "model_3.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 4ms/step - loss: 0.8663 - accuracy: 0.5955\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_3.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados  y metricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings tamaño 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 150, 100)          3507800   \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 15000)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               1920128   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5436379 (20.74 MB)\n",
      "Trainable params: 1928579 (7.36 MB)\n",
      "Non-trainable params: 3507800 (13.38 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Si tienes múltiples clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73       909\n",
      "           1       0.61      0.71      0.65       909\n",
      "           2       0.74      0.73      0.74       909\n",
      "\n",
      "    accuracy                           0.70      2727\n",
      "   macro avg       0.71      0.70      0.71      2727\n",
      "weighted avg       0.71      0.70      0.71      2727\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings tamaño 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 150, 200)          7015600   \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 30000)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               3840128   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10864179 (41.44 MB)\n",
      "Trainable params: 3848579 (14.68 MB)\n",
      "Non-trainable params: 7015600 (26.76 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_2.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.27      0.40       909\n",
      "           1       0.61      0.49      0.54       909\n",
      "           2       0.47      0.88      0.61       909\n",
      "\n",
      "    accuracy                           0.55      2727\n",
      "   macro avg       0.63      0.55      0.52      2727\n",
      "weighted avg       0.63      0.55      0.52      2727\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings tamaño 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 150, 300)          10523400  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 45000)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               5760128   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16291979 (62.15 MB)\n",
      "Trainable params: 5768579 (22.01 MB)\n",
      "Non-trainable params: 10523400 (40.14 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_3.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.44      0.56       909\n",
      "           1       0.62      0.49      0.54       909\n",
      "           2       0.52      0.86      0.65       909\n",
      "\n",
      "    accuracy                           0.60      2727\n",
      "   macro avg       0.64      0.60      0.59      2727\n",
      "weighted avg       0.64      0.60      0.59      2727\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred_classes)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
