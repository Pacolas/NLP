{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PUNTO 3 - ARQUITECTURA 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descarga de librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from keras.layers import Embedding, Flatten, Dense, Dropout\n",
    "import os\n",
    "from gensim.utils import simple_preprocess\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.layers import Dense, Embedding, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESAMIENTO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se encontraron 9 libros en la carpeta /books\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "books_folder = './books/'\n",
    "\n",
    "\n",
    "book_files = [f for f in os.listdir(books_folder) if f.endswith('.txt')]\n",
    "\n",
    "names = []\n",
    "books_texts = []\n",
    "for book_file in book_files:\n",
    "    with open(os.path.join(books_folder, book_file), 'r', encoding='utf-8') as file:\n",
    "        books_texts.append(file.read())\n",
    "        names.append(book_file.split('_')[0])\n",
    "\n",
    "print(f'Se encontraron {len(book_files)} libros en la carpeta /books')\n",
    "processed_books = [\" \".join(simple_preprocess(text)) for text in books_texts]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividir textos en fragmentos con su respectiva etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_fragments(text, fragment_size=150):\n",
    "    words = text.split()\n",
    "    fragments = [words[i:i + fragment_size] for i in range(0, len(words), fragment_size)]\n",
    "    return [' '.join(fragment) for fragment in fragments]\n",
    "\n",
    "\n",
    "fragment_size = 150  \n",
    "fragmented_books = []\n",
    "fragment_labels = []\n",
    "\n",
    "for i, book_text in enumerate(books_texts):\n",
    "    fragments = split_into_fragments(book_text, fragment_size=fragment_size)\n",
    "    fragmented_books.extend(fragments)\n",
    "    fragment_labels.extend([names[i]] * len(fragments))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revision de fragmentos por etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7553\n",
      "{'tolstoy': 4544, 'forster': 1520, 'vonarnin': 1489}\n"
     ]
    }
   ],
   "source": [
    "print(len(fragment_labels))\n",
    "dic = {}\n",
    "for i in fragment_labels:\n",
    "    dic[i] = dic.get(i, 0)+ 1\n",
    "\n",
    "print(dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(fragmented_books)\n",
    "X = tokenizer.texts_to_sequences(fragmented_books)\n",
    "\n",
    "X = pad_sequences(X, maxlen=fragment_size)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(fragment_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Division entre test y train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: imbalanced-learn in /Users/nicolasp/Library/Python/3.8/lib/python/site-packages (0.12.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/nicolasp/Library/Python/3.8/lib/python/site-packages (from imbalanced-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/nicolasp/Library/Python/3.8/lib/python/site-packages (from imbalanced-learn) (1.9.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Users/nicolasp/Library/Python/3.8/lib/python/site-packages (from imbalanced-learn) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/nicolasp/Library/Python/3.8/lib/python/site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/nicolasp/Library/Python/3.8/lib/python/site-packages (from imbalanced-learn) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creacion de la matriz de embeddings pre entrenados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings de tama単o 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec  \n",
    "embedding_model_3 = Word2Vec.load('Books_300_EMF.model')\n",
    "vocab_size = len(tokenizer.word_index) + 1  \n",
    "embedding_dim_3 = embedding_model_3.vector_size  \n",
    "embedding_matrix_3 = np.zeros((vocab_size, embedding_dim_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, idx in tokenizer.word_index.items():\n",
    "    if word in embedding_model_3.wv:\n",
    "        embedding_matrix_3[idx] = embedding_model_3.wv[word]\n",
    "    else:\n",
    "        embedding_matrix_3[idx] = np.zeros(embedding_dim_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding de tama単o 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec  \n",
    "embedding_model_2 = Word2Vec.load('Books_200_EMF.model')\n",
    "vocab_size = len(tokenizer.word_index) + 1  \n",
    "embedding_dim_2 = embedding_model_2.vector_size  \n",
    "embedding_matrix_2 = np.zeros((vocab_size, embedding_dim_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, idx in tokenizer.word_index.items():\n",
    "    if word in embedding_model_2.wv:\n",
    "        embedding_matrix_2[idx] = embedding_model_2.wv[word]\n",
    "    else:\n",
    "        embedding_matrix_2[idx] = np.zeros(embedding_dim_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings de tama単o 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec  \n",
    "embedding_model = Word2Vec.load('Books_100_EMF.model')\n",
    "vocab_size = len(tokenizer.word_index) + 1  \n",
    "embedding_dim = embedding_model.vector_size  \n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, idx in tokenizer.word_index.items():\n",
    "    if word in embedding_model.wv:\n",
    "        embedding_matrix[idx] = embedding_model.wv[word]\n",
    "    else:\\\n",
    "        embedding_matrix[idx] = np.zeros(embedding_dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creacion de la red feed-forward: Arquitectura 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings tama単o 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 150, 300)          10523400  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 45000)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               11520256  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22085003 (84.25 MB)\n",
      "Trainable params: 11561603 (44.10 MB)\n",
      "Non-trainable params: 10523400 (40.14 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "model_3 = Sequential()\n",
    "\n",
    "model_3.add(Embedding(input_dim=vocab_size, \n",
    "                    output_dim=embedding_dim_3, \n",
    "                    weights=[embedding_matrix_3],  \n",
    "                    input_length=fragment_size,  \n",
    "                    trainable=False))  \n",
    "\n",
    "model_3.add(Flatten())\n",
    "\n",
    "model_3.add(Dense(256, activation='relu'))\n",
    "model_3.add(Dropout(0.5))\n",
    "\n",
    "model_3.add(Dense(128, activation='relu'))\n",
    "model_3.add(Dropout(0.5))\n",
    "\n",
    "model_3.add(Dense(64, activation='relu'))\n",
    "\n",
    "model_3.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model_3.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings tama単o 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'forster', 'tolstoy', 'vonarnin'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 3635, 1: 3635, 2: 3635}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "class_distribution = dict(zip(unique, counts))\n",
    "print(class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 150, 200)          7015600   \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 30000)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               7680256   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14737203 (56.22 MB)\n",
      "Trainable params: 7721603 (29.46 MB)\n",
      "Non-trainable params: 7015600 (26.76 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2 = Sequential()\n",
    "\n",
    "model_2.add(Embedding(input_dim=vocab_size, \n",
    "                    output_dim=embedding_dim_2, \n",
    "                    weights=[embedding_matrix_2],  \n",
    "                    input_length=fragment_size,  \n",
    "                    trainable=False))  \n",
    "\n",
    "model_2.add(Flatten())\n",
    "\n",
    "model_2.add(Dense(256, activation='relu'))\n",
    "model_2.add(Dropout(0.5))\n",
    "\n",
    "model_2.add(Dense(128, activation='relu'))\n",
    "model_2.add(Dropout(0.5))\n",
    "\n",
    "model_2.add(Dense(64, activation='relu'))\n",
    "\n",
    "model_2.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model_2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings tama単o 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 150, 100)          3507800   \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 15000)             0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 256)               3840256   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7389403 (28.19 MB)\n",
      "Trainable params: 3881603 (14.81 MB)\n",
      "Non-trainable params: 3507800 (13.38 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim=vocab_size, \n",
    "                    output_dim=embedding_dim, \n",
    "                    weights=[embedding_matrix],  \n",
    "                    input_length=fragment_size,  \n",
    "                    trainable=False))  \n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de la red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings tama単o 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "341/341 [==============================] - 4s 11ms/step - loss: 1.1684 - accuracy: 0.3394 - val_loss: 1.0930 - val_accuracy: 0.3762\n",
      "Epoch 2/100\n",
      "341/341 [==============================] - 4s 10ms/step - loss: 1.1026 - accuracy: 0.3541 - val_loss: 1.0915 - val_accuracy: 0.3715\n",
      "Epoch 3/100\n",
      "341/341 [==============================] - 3s 10ms/step - loss: 1.0854 - accuracy: 0.3756 - val_loss: 1.0740 - val_accuracy: 0.4067\n",
      "Epoch 4/100\n",
      "341/341 [==============================] - 4s 11ms/step - loss: 1.0705 - accuracy: 0.3970 - val_loss: 1.0520 - val_accuracy: 0.4411\n",
      "Epoch 5/100\n",
      "341/341 [==============================] - 4s 11ms/step - loss: 1.0484 - accuracy: 0.4171 - val_loss: 1.0294 - val_accuracy: 0.4507\n",
      "Epoch 6/100\n",
      "341/341 [==============================] - 3s 10ms/step - loss: 1.0152 - accuracy: 0.4503 - val_loss: 0.9961 - val_accuracy: 0.5064\n",
      "Epoch 7/100\n",
      "341/341 [==============================] - 3s 10ms/step - loss: 0.9775 - accuracy: 0.4777 - val_loss: 0.9708 - val_accuracy: 0.4987\n",
      "Epoch 8/100\n",
      "341/341 [==============================] - 3s 10ms/step - loss: 0.9480 - accuracy: 0.4976 - val_loss: 0.9395 - val_accuracy: 0.5196\n",
      "Epoch 9/100\n",
      "341/341 [==============================] - 3s 10ms/step - loss: 0.9213 - accuracy: 0.5078 - val_loss: 0.9038 - val_accuracy: 0.5449\n",
      "Epoch 10/100\n",
      "341/341 [==============================] - 4s 10ms/step - loss: 0.8928 - accuracy: 0.5220 - val_loss: 0.8703 - val_accuracy: 0.5739\n",
      "Epoch 11/100\n",
      "341/341 [==============================] - 4s 11ms/step - loss: 0.8687 - accuracy: 0.5598 - val_loss: 0.8538 - val_accuracy: 0.6087\n",
      "Epoch 12/100\n",
      "341/341 [==============================] - 4s 12ms/step - loss: 0.8553 - accuracy: 0.5802 - val_loss: 0.8376 - val_accuracy: 0.6304\n",
      "Epoch 13/100\n",
      "341/341 [==============================] - 4s 11ms/step - loss: 0.8262 - accuracy: 0.5973 - val_loss: 0.8303 - val_accuracy: 0.6245\n",
      "Epoch 14/100\n",
      "341/341 [==============================] - 4s 12ms/step - loss: 0.8146 - accuracy: 0.6056 - val_loss: 0.7946 - val_accuracy: 0.6406\n",
      "Epoch 15/100\n",
      "341/341 [==============================] - 4s 12ms/step - loss: 0.7986 - accuracy: 0.6208 - val_loss: 0.7840 - val_accuracy: 0.6410\n",
      "Epoch 16/100\n",
      "341/341 [==============================] - 4s 11ms/step - loss: 0.7803 - accuracy: 0.6315 - val_loss: 0.7906 - val_accuracy: 0.6494\n",
      "Epoch 17/100\n",
      "341/341 [==============================] - 4s 10ms/step - loss: 0.7672 - accuracy: 0.6416 - val_loss: 0.7726 - val_accuracy: 0.6520\n",
      "Epoch 18/100\n",
      "341/341 [==============================] - 4s 11ms/step - loss: 0.7569 - accuracy: 0.6459 - val_loss: 0.7488 - val_accuracy: 0.6641\n",
      "Epoch 19/100\n",
      "341/341 [==============================] - 4s 11ms/step - loss: 0.7372 - accuracy: 0.6601 - val_loss: 0.7606 - val_accuracy: 0.6612\n",
      "Epoch 20/100\n",
      "341/341 [==============================] - 4s 12ms/step - loss: 0.7292 - accuracy: 0.6654 - val_loss: 0.7524 - val_accuracy: 0.6480\n",
      "Epoch 21/100\n",
      "341/341 [==============================] - 4s 10ms/step - loss: 0.7109 - accuracy: 0.6752 - val_loss: 0.7318 - val_accuracy: 0.6733\n",
      "Epoch 22/100\n",
      "341/341 [==============================] - 4s 11ms/step - loss: 0.7233 - accuracy: 0.6691 - val_loss: 0.7502 - val_accuracy: 0.6447\n",
      "Epoch 23/100\n",
      "341/341 [==============================] - 4s 11ms/step - loss: 0.6891 - accuracy: 0.6914 - val_loss: 0.7661 - val_accuracy: 0.6252\n",
      "Epoch 24/100\n",
      "341/341 [==============================] - 4s 12ms/step - loss: 0.6971 - accuracy: 0.6903 - val_loss: 0.7117 - val_accuracy: 0.6839\n",
      "Epoch 25/100\n",
      "341/341 [==============================] - 4s 12ms/step - loss: 0.6891 - accuracy: 0.6918 - val_loss: 0.7276 - val_accuracy: 0.6740\n",
      "Epoch 26/100\n",
      "341/341 [==============================] - 3s 9ms/step - loss: 0.6840 - accuracy: 0.6994 - val_loss: 0.6952 - val_accuracy: 0.7081\n",
      "Epoch 27/100\n",
      "341/341 [==============================] - 3s 9ms/step - loss: 0.6615 - accuracy: 0.7103 - val_loss: 0.7153 - val_accuracy: 0.6854\n",
      "Epoch 28/100\n",
      "341/341 [==============================] - 3s 9ms/step - loss: 0.6743 - accuracy: 0.7057 - val_loss: 0.7029 - val_accuracy: 0.6817\n",
      "Epoch 29/100\n",
      "341/341 [==============================] - 5s 13ms/step - loss: 0.6645 - accuracy: 0.7136 - val_loss: 0.6871 - val_accuracy: 0.6945\n",
      "Epoch 30/100\n",
      "341/341 [==============================] - 4s 12ms/step - loss: 0.6581 - accuracy: 0.7101 - val_loss: 0.7261 - val_accuracy: 0.6810\n",
      "Epoch 31/100\n",
      "341/341 [==============================] - 4s 12ms/step - loss: 0.6355 - accuracy: 0.7243 - val_loss: 0.6612 - val_accuracy: 0.7217\n",
      "Epoch 32/100\n",
      "341/341 [==============================] - 4s 10ms/step - loss: 0.6297 - accuracy: 0.7283 - val_loss: 0.7016 - val_accuracy: 0.6850\n",
      "Epoch 33/100\n",
      "341/341 [==============================] - 4s 11ms/step - loss: 0.6230 - accuracy: 0.7326 - val_loss: 0.6662 - val_accuracy: 0.7136\n",
      "Epoch 34/100\n",
      "341/341 [==============================] - 4s 11ms/step - loss: 0.6195 - accuracy: 0.7350 - val_loss: 0.6912 - val_accuracy: 0.6824\n",
      "Epoch 35/100\n",
      "341/341 [==============================] - 4s 12ms/step - loss: 0.6154 - accuracy: 0.7399 - val_loss: 0.6835 - val_accuracy: 0.7081\n",
      "Epoch 36/100\n",
      "341/341 [==============================] - 4s 13ms/step - loss: 0.6153 - accuracy: 0.7419 - val_loss: 0.6728 - val_accuracy: 0.6989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x314d3a310>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings tama単o 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "341/341 [==============================] - 7s 20ms/step - loss: 1.2006 - accuracy: 0.3375 - val_loss: 1.0952 - val_accuracy: 0.3352\n",
      "Epoch 2/100\n",
      "341/341 [==============================] - 7s 21ms/step - loss: 1.0986 - accuracy: 0.3486 - val_loss: 1.0874 - val_accuracy: 0.3891\n",
      "Epoch 3/100\n",
      "341/341 [==============================] - 8s 23ms/step - loss: 1.0882 - accuracy: 0.3763 - val_loss: 1.0706 - val_accuracy: 0.3975\n",
      "Epoch 4/100\n",
      "341/341 [==============================] - 7s 21ms/step - loss: 1.0735 - accuracy: 0.3875 - val_loss: 1.0421 - val_accuracy: 0.4690\n",
      "Epoch 5/100\n",
      "341/341 [==============================] - 7s 21ms/step - loss: 1.0547 - accuracy: 0.4138 - val_loss: 1.0288 - val_accuracy: 0.4683\n",
      "Epoch 6/100\n",
      "341/341 [==============================] - 6s 18ms/step - loss: 1.0410 - accuracy: 0.4293 - val_loss: 1.0158 - val_accuracy: 0.4723\n",
      "Epoch 7/100\n",
      "341/341 [==============================] - 7s 20ms/step - loss: 1.0262 - accuracy: 0.4359 - val_loss: 1.0009 - val_accuracy: 0.4881\n",
      "Epoch 8/100\n",
      "341/341 [==============================] - 7s 21ms/step - loss: 1.0099 - accuracy: 0.4589 - val_loss: 0.9827 - val_accuracy: 0.5255\n",
      "Epoch 9/100\n",
      "341/341 [==============================] - 7s 21ms/step - loss: 0.9991 - accuracy: 0.4688 - val_loss: 0.9605 - val_accuracy: 0.5464\n",
      "Epoch 10/100\n",
      "341/341 [==============================] - 6s 17ms/step - loss: 0.9770 - accuracy: 0.4929 - val_loss: 0.9599 - val_accuracy: 0.5365\n",
      "Epoch 11/100\n",
      "341/341 [==============================] - 6s 19ms/step - loss: 0.9611 - accuracy: 0.5042 - val_loss: 0.9396 - val_accuracy: 0.5552\n",
      "Epoch 12/100\n",
      "341/341 [==============================] - 6s 18ms/step - loss: 0.9432 - accuracy: 0.5178 - val_loss: 0.9274 - val_accuracy: 0.5537\n",
      "Epoch 13/100\n",
      "341/341 [==============================] - 8s 25ms/step - loss: 0.9332 - accuracy: 0.5265 - val_loss: 0.9072 - val_accuracy: 0.5713\n",
      "Epoch 14/100\n",
      "341/341 [==============================] - 8s 23ms/step - loss: 0.9196 - accuracy: 0.5396 - val_loss: 0.8968 - val_accuracy: 0.5875\n",
      "Epoch 15/100\n",
      "341/341 [==============================] - 7s 19ms/step - loss: 0.9107 - accuracy: 0.5505 - val_loss: 0.8882 - val_accuracy: 0.5970\n",
      "Epoch 16/100\n",
      "341/341 [==============================] - 7s 21ms/step - loss: 0.8962 - accuracy: 0.5671 - val_loss: 0.8760 - val_accuracy: 0.5981\n",
      "Epoch 17/100\n",
      "341/341 [==============================] - 7s 19ms/step - loss: 0.8741 - accuracy: 0.5835 - val_loss: 0.8481 - val_accuracy: 0.6124\n",
      "Epoch 18/100\n",
      "341/341 [==============================] - 6s 19ms/step - loss: 0.8629 - accuracy: 0.5900 - val_loss: 0.8494 - val_accuracy: 0.6069\n",
      "Epoch 19/100\n",
      "341/341 [==============================] - 7s 19ms/step - loss: 0.8592 - accuracy: 0.5935 - val_loss: 0.8427 - val_accuracy: 0.6164\n",
      "Epoch 20/100\n",
      "341/341 [==============================] - 6s 18ms/step - loss: 0.8421 - accuracy: 0.6093 - val_loss: 0.8223 - val_accuracy: 0.6329\n",
      "Epoch 21/100\n",
      "341/341 [==============================] - 6s 19ms/step - loss: 0.8349 - accuracy: 0.6205 - val_loss: 0.8150 - val_accuracy: 0.6293\n",
      "Epoch 22/100\n",
      "341/341 [==============================] - 7s 20ms/step - loss: 0.8321 - accuracy: 0.6159 - val_loss: 0.8077 - val_accuracy: 0.6450\n",
      "Epoch 23/100\n",
      "341/341 [==============================] - 7s 20ms/step - loss: 0.8034 - accuracy: 0.6374 - val_loss: 0.8016 - val_accuracy: 0.6289\n",
      "Epoch 24/100\n",
      "341/341 [==============================] - 6s 18ms/step - loss: 0.7983 - accuracy: 0.6374 - val_loss: 0.7706 - val_accuracy: 0.6784\n",
      "Epoch 25/100\n",
      "341/341 [==============================] - 8s 24ms/step - loss: 0.7860 - accuracy: 0.6459 - val_loss: 0.7708 - val_accuracy: 0.6615\n",
      "Epoch 26/100\n",
      "341/341 [==============================] - 7s 19ms/step - loss: 0.7862 - accuracy: 0.6457 - val_loss: 0.7683 - val_accuracy: 0.6604\n",
      "Epoch 27/100\n",
      "341/341 [==============================] - 7s 20ms/step - loss: 0.7814 - accuracy: 0.6492 - val_loss: 0.7843 - val_accuracy: 0.6553\n",
      "Epoch 28/100\n",
      "341/341 [==============================] - 7s 19ms/step - loss: 0.7621 - accuracy: 0.6607 - val_loss: 0.7897 - val_accuracy: 0.6311\n",
      "Epoch 29/100\n",
      "341/341 [==============================] - 7s 19ms/step - loss: 0.7581 - accuracy: 0.6723 - val_loss: 0.7726 - val_accuracy: 0.6491\n",
      "Epoch 30/100\n",
      "341/341 [==============================] - 7s 19ms/step - loss: 0.7569 - accuracy: 0.6699 - val_loss: 0.7541 - val_accuracy: 0.6630\n",
      "Epoch 31/100\n",
      "341/341 [==============================] - 6s 18ms/step - loss: 0.7360 - accuracy: 0.6826 - val_loss: 0.7471 - val_accuracy: 0.6663\n",
      "Epoch 32/100\n",
      "341/341 [==============================] - 7s 20ms/step - loss: 0.7287 - accuracy: 0.6827 - val_loss: 0.7384 - val_accuracy: 0.6740\n",
      "Epoch 33/100\n",
      "341/341 [==============================] - 8s 23ms/step - loss: 0.7373 - accuracy: 0.6819 - val_loss: 0.7118 - val_accuracy: 0.6931\n",
      "Epoch 34/100\n",
      "341/341 [==============================] - 7s 22ms/step - loss: 0.7186 - accuracy: 0.6928 - val_loss: 0.7260 - val_accuracy: 0.6839\n",
      "Epoch 35/100\n",
      "341/341 [==============================] - 7s 22ms/step - loss: 0.7385 - accuracy: 0.6779 - val_loss: 0.6991 - val_accuracy: 0.7114\n",
      "Epoch 36/100\n",
      "341/341 [==============================] - 7s 19ms/step - loss: 0.7204 - accuracy: 0.6899 - val_loss: 0.7126 - val_accuracy: 0.6949\n",
      "Epoch 37/100\n",
      "341/341 [==============================] - 7s 21ms/step - loss: 0.7104 - accuracy: 0.6960 - val_loss: 0.7105 - val_accuracy: 0.6810\n",
      "Epoch 38/100\n",
      "341/341 [==============================] - 7s 20ms/step - loss: 0.6996 - accuracy: 0.7011 - val_loss: 0.7155 - val_accuracy: 0.6982\n",
      "Epoch 39/100\n",
      "341/341 [==============================] - 7s 19ms/step - loss: 0.6873 - accuracy: 0.7078 - val_loss: 0.7442 - val_accuracy: 0.6491\n",
      "Epoch 40/100\n",
      "341/341 [==============================] - 7s 21ms/step - loss: 0.6875 - accuracy: 0.7111 - val_loss: 0.6937 - val_accuracy: 0.7180\n",
      "Epoch 41/100\n",
      "341/341 [==============================] - 7s 20ms/step - loss: 0.6922 - accuracy: 0.7061 - val_loss: 0.7251 - val_accuracy: 0.6806\n",
      "Epoch 42/100\n",
      "341/341 [==============================] - 6s 19ms/step - loss: 0.6893 - accuracy: 0.7088 - val_loss: 0.7016 - val_accuracy: 0.6945\n",
      "Epoch 43/100\n",
      "341/341 [==============================] - 7s 19ms/step - loss: 0.6739 - accuracy: 0.7189 - val_loss: 0.7034 - val_accuracy: 0.7063\n",
      "Epoch 44/100\n",
      "341/341 [==============================] - 7s 19ms/step - loss: 0.6711 - accuracy: 0.7210 - val_loss: 0.6941 - val_accuracy: 0.6953\n",
      "Epoch 45/100\n",
      "341/341 [==============================] - 7s 19ms/step - loss: 0.6720 - accuracy: 0.7197 - val_loss: 0.7001 - val_accuracy: 0.6828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x35cf5d880>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping_2 = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "model_2.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 5ms/step - loss: 0.6937 - accuracy: 0.7180\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings tama単o 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "341/341 [==============================] - 10s 28ms/step - loss: 1.2083 - accuracy: 0.3288 - val_loss: 1.0958 - val_accuracy: 0.3553\n",
      "Epoch 2/100\n",
      "341/341 [==============================] - 11s 32ms/step - loss: 1.0993 - accuracy: 0.3427 - val_loss: 1.0879 - val_accuracy: 0.3682\n",
      "Epoch 3/100\n",
      "341/341 [==============================] - 10s 29ms/step - loss: 1.0905 - accuracy: 0.3543 - val_loss: 1.0711 - val_accuracy: 0.3905\n",
      "Epoch 4/100\n",
      "341/341 [==============================] - 13s 38ms/step - loss: 1.0730 - accuracy: 0.3910 - val_loss: 1.0639 - val_accuracy: 0.4162\n",
      "Epoch 5/100\n",
      "341/341 [==============================] - 11s 33ms/step - loss: 1.0588 - accuracy: 0.4062 - val_loss: 1.0411 - val_accuracy: 0.4470\n",
      "Epoch 6/100\n",
      "341/341 [==============================] - 12s 35ms/step - loss: 1.0376 - accuracy: 0.4268 - val_loss: 1.0093 - val_accuracy: 0.4862\n",
      "Epoch 7/100\n",
      "341/341 [==============================] - 11s 33ms/step - loss: 1.0233 - accuracy: 0.4397 - val_loss: 1.0057 - val_accuracy: 0.4928\n",
      "Epoch 8/100\n",
      "341/341 [==============================] - 9s 28ms/step - loss: 1.0145 - accuracy: 0.4535 - val_loss: 0.9853 - val_accuracy: 0.5152\n",
      "Epoch 9/100\n",
      "341/341 [==============================] - 12s 36ms/step - loss: 0.9968 - accuracy: 0.4644 - val_loss: 0.9603 - val_accuracy: 0.5464\n",
      "Epoch 10/100\n",
      "341/341 [==============================] - 13s 38ms/step - loss: 0.9783 - accuracy: 0.4781 - val_loss: 0.9617 - val_accuracy: 0.5482\n",
      "Epoch 11/100\n",
      "341/341 [==============================] - 31s 91ms/step - loss: 0.9661 - accuracy: 0.4923 - val_loss: 0.9315 - val_accuracy: 0.5757\n",
      "Epoch 12/100\n",
      "341/341 [==============================] - 16s 45ms/step - loss: 0.9623 - accuracy: 0.5015 - val_loss: 0.9380 - val_accuracy: 0.5699\n",
      "Epoch 13/100\n",
      "341/341 [==============================] - 13s 38ms/step - loss: 0.9463 - accuracy: 0.5225 - val_loss: 0.9172 - val_accuracy: 0.5845\n",
      "Epoch 14/100\n",
      "341/341 [==============================] - 11s 32ms/step - loss: 0.9296 - accuracy: 0.5343 - val_loss: 0.9037 - val_accuracy: 0.5974\n",
      "Epoch 15/100\n",
      "341/341 [==============================] - 12s 34ms/step - loss: 0.9141 - accuracy: 0.5481 - val_loss: 0.9000 - val_accuracy: 0.5963\n",
      "Epoch 16/100\n",
      "341/341 [==============================] - 11s 32ms/step - loss: 0.9155 - accuracy: 0.5546 - val_loss: 0.8838 - val_accuracy: 0.6069\n",
      "Epoch 17/100\n",
      "341/341 [==============================] - 12s 35ms/step - loss: 0.8939 - accuracy: 0.5661 - val_loss: 0.8479 - val_accuracy: 0.6256\n",
      "Epoch 18/100\n",
      "341/341 [==============================] - 11s 32ms/step - loss: 0.8822 - accuracy: 0.5762 - val_loss: 0.8460 - val_accuracy: 0.6208\n",
      "Epoch 19/100\n",
      "341/341 [==============================] - 10s 30ms/step - loss: 0.8723 - accuracy: 0.5825 - val_loss: 0.8517 - val_accuracy: 0.6150\n",
      "Epoch 20/100\n",
      "341/341 [==============================] - 11s 34ms/step - loss: 0.8733 - accuracy: 0.5879 - val_loss: 0.8278 - val_accuracy: 0.6366\n",
      "Epoch 21/100\n",
      "341/341 [==============================] - 12s 35ms/step - loss: 0.8577 - accuracy: 0.5996 - val_loss: 0.8462 - val_accuracy: 0.5992\n",
      "Epoch 22/100\n",
      "341/341 [==============================] - 12s 35ms/step - loss: 0.8447 - accuracy: 0.6114 - val_loss: 0.8135 - val_accuracy: 0.6498\n",
      "Epoch 23/100\n",
      "341/341 [==============================] - 10s 29ms/step - loss: 0.8453 - accuracy: 0.6076 - val_loss: 0.8331 - val_accuracy: 0.6186\n",
      "Epoch 24/100\n",
      "341/341 [==============================] - 10s 29ms/step - loss: 0.8410 - accuracy: 0.6121 - val_loss: 0.8396 - val_accuracy: 0.6021\n",
      "Epoch 25/100\n",
      "341/341 [==============================] - 10s 30ms/step - loss: 0.8465 - accuracy: 0.6031 - val_loss: 0.8303 - val_accuracy: 0.6197\n",
      "Epoch 26/100\n",
      "341/341 [==============================] - 10s 30ms/step - loss: 0.8294 - accuracy: 0.6247 - val_loss: 0.7911 - val_accuracy: 0.6447\n",
      "Epoch 27/100\n",
      "341/341 [==============================] - 12s 34ms/step - loss: 0.8114 - accuracy: 0.6356 - val_loss: 0.7934 - val_accuracy: 0.6370\n",
      "Epoch 28/100\n",
      "341/341 [==============================] - 11s 32ms/step - loss: 0.8095 - accuracy: 0.6318 - val_loss: 0.7958 - val_accuracy: 0.6494\n",
      "Epoch 29/100\n",
      "341/341 [==============================] - 13s 38ms/step - loss: 0.8094 - accuracy: 0.6362 - val_loss: 0.7708 - val_accuracy: 0.6538\n",
      "Epoch 30/100\n",
      "341/341 [==============================] - 14s 41ms/step - loss: 0.7930 - accuracy: 0.6459 - val_loss: 0.7698 - val_accuracy: 0.6586\n",
      "Epoch 31/100\n",
      "341/341 [==============================] - 13s 37ms/step - loss: 0.7886 - accuracy: 0.6485 - val_loss: 0.7534 - val_accuracy: 0.6744\n",
      "Epoch 32/100\n",
      "341/341 [==============================] - 14s 41ms/step - loss: 0.7685 - accuracy: 0.6637 - val_loss: 0.7608 - val_accuracy: 0.6498\n",
      "Epoch 33/100\n",
      "341/341 [==============================] - 11s 33ms/step - loss: 0.7838 - accuracy: 0.6526 - val_loss: 0.7459 - val_accuracy: 0.6740\n",
      "Epoch 34/100\n",
      "341/341 [==============================] - 11s 32ms/step - loss: 0.7615 - accuracy: 0.6625 - val_loss: 0.7404 - val_accuracy: 0.6766\n",
      "Epoch 35/100\n",
      "341/341 [==============================] - 9s 27ms/step - loss: 0.7611 - accuracy: 0.6613 - val_loss: 0.7478 - val_accuracy: 0.6634\n",
      "Epoch 36/100\n",
      "341/341 [==============================] - 11s 33ms/step - loss: 0.7493 - accuracy: 0.6768 - val_loss: 0.7611 - val_accuracy: 0.6505\n",
      "Epoch 37/100\n",
      "341/341 [==============================] - 11s 32ms/step - loss: 0.7480 - accuracy: 0.6723 - val_loss: 0.7323 - val_accuracy: 0.6912\n",
      "Epoch 38/100\n",
      "341/341 [==============================] - 10s 30ms/step - loss: 0.7476 - accuracy: 0.6755 - val_loss: 0.7223 - val_accuracy: 0.6956\n",
      "Epoch 39/100\n",
      "341/341 [==============================] - 9s 26ms/step - loss: 0.7396 - accuracy: 0.6829 - val_loss: 0.7253 - val_accuracy: 0.6828\n",
      "Epoch 40/100\n",
      "341/341 [==============================] - 9s 26ms/step - loss: 0.7459 - accuracy: 0.6747 - val_loss: 0.7308 - val_accuracy: 0.6861\n",
      "Epoch 41/100\n",
      "341/341 [==============================] - 10s 29ms/step - loss: 0.7363 - accuracy: 0.6823 - val_loss: 0.7151 - val_accuracy: 0.6931\n",
      "Epoch 42/100\n",
      "341/341 [==============================] - 10s 28ms/step - loss: 0.7228 - accuracy: 0.6910 - val_loss: 0.7234 - val_accuracy: 0.6835\n",
      "Epoch 43/100\n",
      "341/341 [==============================] - 9s 27ms/step - loss: 0.7183 - accuracy: 0.6975 - val_loss: 0.7335 - val_accuracy: 0.6879\n",
      "Epoch 44/100\n",
      "341/341 [==============================] - 10s 31ms/step - loss: 0.7092 - accuracy: 0.7003 - val_loss: 0.7017 - val_accuracy: 0.7059\n",
      "Epoch 45/100\n",
      "341/341 [==============================] - 9s 27ms/step - loss: 0.7249 - accuracy: 0.6905 - val_loss: 0.7145 - val_accuracy: 0.6821\n",
      "Epoch 46/100\n",
      "341/341 [==============================] - 10s 28ms/step - loss: 0.7171 - accuracy: 0.6939 - val_loss: 0.7136 - val_accuracy: 0.6894\n",
      "Epoch 47/100\n",
      "341/341 [==============================] - 10s 29ms/step - loss: 0.7064 - accuracy: 0.6982 - val_loss: 0.6972 - val_accuracy: 0.7004\n",
      "Epoch 48/100\n",
      "341/341 [==============================] - 10s 28ms/step - loss: 0.7038 - accuracy: 0.7075 - val_loss: 0.6859 - val_accuracy: 0.6971\n",
      "Epoch 49/100\n",
      "341/341 [==============================] - 9s 27ms/step - loss: 0.6933 - accuracy: 0.7062 - val_loss: 0.6883 - val_accuracy: 0.7121\n",
      "Epoch 50/100\n",
      "341/341 [==============================] - 10s 28ms/step - loss: 0.6827 - accuracy: 0.7195 - val_loss: 0.6860 - val_accuracy: 0.7059\n",
      "Epoch 51/100\n",
      "341/341 [==============================] - 11s 31ms/step - loss: 0.6785 - accuracy: 0.7197 - val_loss: 0.6606 - val_accuracy: 0.7429\n",
      "Epoch 52/100\n",
      "341/341 [==============================] - 11s 31ms/step - loss: 0.6804 - accuracy: 0.7163 - val_loss: 0.6938 - val_accuracy: 0.7213\n",
      "Epoch 53/100\n",
      "341/341 [==============================] - 10s 29ms/step - loss: 0.6731 - accuracy: 0.7259 - val_loss: 0.7198 - val_accuracy: 0.6806\n",
      "Epoch 54/100\n",
      "341/341 [==============================] - 10s 30ms/step - loss: 0.6674 - accuracy: 0.7248 - val_loss: 0.6920 - val_accuracy: 0.6986\n",
      "Epoch 55/100\n",
      "341/341 [==============================] - 10s 30ms/step - loss: 0.6808 - accuracy: 0.7174 - val_loss: 0.6973 - val_accuracy: 0.7099\n",
      "Epoch 56/100\n",
      "341/341 [==============================] - 14s 41ms/step - loss: 0.6561 - accuracy: 0.7320 - val_loss: 0.6819 - val_accuracy: 0.7195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x318514a60>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping_3 = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "model_3.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 7ms/step - loss: 0.6606 - accuracy: 0.7429\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_3.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados  y metricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings tama単o 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 150, 100)          3507800   \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 15000)             0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 256)               3840256   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7389403 (28.19 MB)\n",
      "Trainable params: 3881603 (14.81 MB)\n",
      "Non-trainable params: 3507800 (13.38 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.71      0.77       909\n",
      "           1       0.58      0.76      0.66       909\n",
      "           2       0.83      0.69      0.75       909\n",
      "\n",
      "    accuracy                           0.72      2727\n",
      "   macro avg       0.75      0.72      0.73      2727\n",
      "weighted avg       0.75      0.72      0.73      2727\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings tama単o 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 150, 200)          7015600   \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 30000)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               7680256   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14737203 (56.22 MB)\n",
      "Trainable params: 7721603 (29.46 MB)\n",
      "Non-trainable params: 7015600 (26.76 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_2.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.66      0.74       909\n",
      "           1       0.58      0.76      0.66       909\n",
      "           2       0.80      0.74      0.77       909\n",
      "\n",
      "    accuracy                           0.72      2727\n",
      "   macro avg       0.74      0.72      0.72      2727\n",
      "weighted avg       0.74      0.72      0.72      2727\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings tama単o 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 150, 300)          10523400  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 45000)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               11520256  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22085003 (84.25 MB)\n",
      "Trainable params: 11561603 (44.10 MB)\n",
      "Non-trainable params: 10523400 (40.14 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_3.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.64      0.74       909\n",
      "           1       0.61      0.77      0.68       909\n",
      "           2       0.81      0.82      0.81       909\n",
      "\n",
      "    accuracy                           0.74      2727\n",
      "   macro avg       0.77      0.74      0.75      2727\n",
      "weighted avg       0.77      0.74      0.75      2727\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred_classes)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
